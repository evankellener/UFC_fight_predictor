# -*- coding: utf-8 -*-
"""Untitled42.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kt778LzSsK94pCFSw4HXYZV8VGN7kDoV
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import pandas as pd
from datetime import timedelta
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, log_loss, roc_auc_score

# -----------------------------
# Config
# -----------------------------
DATA_PATH = '../data/tmp/final.csv'  # or "final.csv" if you have not saved the strict one
TEST_START = "2024-01-01"
TRAIN_START = "2009-01-01"
TRAIN_END   = "2023-12-31"      # inclusive

TARGET = "win"

FULL_FEATURES = [
    'age_ratio_difference', 'opp_age_ratio_difference',
    'opp_precomp_elo_change_5', 'precomp_elo', 'opp_precomp_elo',
    'precomp_tdavg', 'opp_precomp_tdavg', 'opp_precomp_tddef',
    'opp_precomp_sapm5', 'precomp_tddef', 'precomp_sapm5',
    'precomp_headacc_perc3', 'opp_precomp_headacc_perc3',
    'precomp_totalacc_perc3', 'precomp_elo_change_5', 'REACH', 'opp_REACH',
    'precomp_legacc_perc5', 'opp_precomp_totalacc_perc3',
    'opp_precomp_legacc_perc5', 'opp_precomp_clinchacc_perc5',
    'precomp_clinchacc_perc5', 'precomp_winsum3', 'opp_precomp_winsum3',
    'opp_precomp_sapm', 'precomp_sapm', 'opp_precomp_totalacc_perc',
    'precomp_totalacc_perc', 'precomp_groundacc_perc5',
    'opp_precomp_groundacc_perc5', 'precomp_losssum5',
    'opp_precomp_losssum5', 'age', 'opp_age',
    'precomp_strike_elo', 'opp_precomp_strike_elo'
]

# Map of precomp -> postcomp for carry forward
PRE_TO_POST_MAP = {
    'precomp_elo': 'postcomp_elo',
    'precomp_tdavg': 'postcomp_tdavg',
    'precomp_tddef': 'postcomp_tddef',
    'precomp_sapm5': 'postcomp_sapm5',
    'precomp_headacc_perc3': 'postcomp_headacc_perc3',
    'precomp_totalacc_perc3': 'postcomp_totalacc_perc3',
    'precomp_elo_change_5': 'postcomp_elo_change_5',
    'REACH': 'REACH',
    'precomp_legacc_perc5': 'postcomp_legacc_perc5',
    'precomp_clinchacc_perc5': 'postcomp_clinchacc_perc5',
    'precomp_winsum3': 'postcomp_winsum3',
    'precomp_sapm': 'postcomp_sapm',
    'precomp_totalacc_perc': 'postcomp_totalacc_perc',
    'precomp_groundacc_perc5': 'postcomp_groundacc_perc5',
    'precomp_losssum5': 'postcomp_losssum5',
    'precomp_strike_elo': 'postcomp_strike_elo',
}

# -----------------------------
# Helpers
# -----------------------------
def truncate_round(x):
    if pd.isna(x):
        return np.nan
    x = float(x)
    truncated = int(x * 10000) / 10000.0   # cut at 4th decimal
    return round(truncated, 2)             # then round to 2

def apply_elo_decay(x, gap_days, threshold=365, decay=0.978):
    if pd.isna(x):
        return np.nan
    val = float(x)
    if gap_days is not None and gap_days >= threshold:
        val = val * decay
    return truncate_round(val)

def compute_age(dob_str, fight_date):
    dob = pd.to_datetime(str(dob_str), errors='coerce')
    if pd.isna(dob) or pd.isna(fight_date):
        return np.nan
    return (fight_date - dob).days / 365.25

def add_prev_index_per_fighter(df_sorted):
    prev_idx = np.full(len(df_sorted), np.nan)
    for _, grp in df_sorted.groupby('FIGHTER'):
        idxs = grp.index.to_list()
        for i in range(1, len(idxs)):
            prev_idx[idxs[i]] = idxs[i - 1]
    return prev_idx

def build_inferred_test_features(df, test_start='2024-01-01'):
    """Return a copy of df where for rows with DATE >= test_start,
    precomp_* features are overwritten from the previous fight's postcomp_*,
    with Elo decay and age recompute. Uses truncate_round for consistency."""
    out = df.copy()
    out['DATE'] = pd.to_datetime(out['DATE'], errors='coerce')
    out = out.sort_values(['FIGHTER', 'DATE'], kind='mergesort').reset_index(drop=True)
    out['prev_idx'] = add_prev_index_per_fighter(out)

    has_opp_dob = 'OPP_DOB' in out.columns

    test_mask = out['DATE'] >= pd.Timestamp(test_start)
    for idx in out.index[test_mask]:
        prv = out.at[idx, 'prev_idx']
        if pd.isna(prv):
            continue
        prv = int(prv)
        gap_days = (out.at[idx, 'DATE'] - out.at[prv, 'DATE']).days if pd.notna(out.at[prv, 'DATE']) else None

        for pre_feat, post_feat in PRE_TO_POST_MAP.items():
            prev_val = out.at[prv, post_feat] if post_feat in out.columns else np.nan
            if pre_feat == 'precomp_elo':
                new_val = apply_elo_decay(prev_val, gap_days)
            else:
                new_val = truncate_round(prev_val)
            out.at[idx, pre_feat] = new_val

        # Recompute ages and ratios on the fight date
        if 'DOB' in out.columns:
            out.at[idx, 'age'] = truncate_round(compute_age(out.at[idx, 'DOB'], out.at[idx, 'DATE']))
        if has_opp_dob:
            out.at[idx, 'opp_age'] = truncate_round(compute_age(out.at[idx, 'OPP_DOB'], out.at[idx, 'DATE']))

        a, oa = out.at[idx, 'age'], out.at[idx, 'opp_age']
        if pd.notna(a) and pd.notna(oa) and oa != 0:
            out.at[idx, 'age_ratio_difference'] = truncate_round(a / oa - 1.0)
            out.at[idx, 'opp_age_ratio_difference'] = truncate_round(oa / a - 1.0)

    return out

def coerce_numeric(df, cols):
    out = df.copy()
    for c in cols:
        if c in out.columns:
            out[c] = pd.to_numeric(out[c], errors='coerce')
        else:
            out[c] = np.nan
    return out

def fit_and_eval(X_train, y_train, X_test, y_test):
    pipe = Pipeline([
        ('scaler', StandardScaler(with_mean=True, with_std=True)),
        ('logreg', LogisticRegression(
            max_iter=1500,
            solver='saga',
            C=1.0,
            n_jobs=-1,
            penalty='l2',
            random_state=42
        ))
    ])
    pipe.fit(X_train, y_train)
    probs = pipe.predict_proba(X_test)[:, 1]
    preds = (probs >= 0.5).astype(int)
    return {
        "accuracy": accuracy_score(y_test, preds),
        "logloss": log_loss(y_test, probs),
        "auc": roc_auc_score(y_test, probs),
    }

# -----------------------------
# Load data
# -----------------------------
df = pd.read_csv(DATA_PATH, low_memory=False)
df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
df = df.sort_values(['FIGHTER','DATE'], kind='mergesort').reset_index(drop=True)
df = df.dropna(subset=[TARGET])  # keep rows with known target

# Train and test splits by calendar date
train = df[(df['DATE'] >= TRAIN_START) & (df['DATE'] <= TRAIN_END)].copy()
test_actual = df[df['DATE'] >= TEST_START].copy()

# Build inferred copy for the same test window
df_inf = build_inferred_test_features(df, test_start=TEST_START)
test_inferred = df_inf[df_inf['DATE'] >= TEST_START].copy()

# -----------------------------
# Prepare matrices
# -----------------------------
# Convert features to numeric and impute with medians from train
train_num = coerce_numeric(train, FULL_FEATURES)
testA_num = coerce_numeric(test_actual, FULL_FEATURES)
testI_num = coerce_numeric(test_inferred, FULL_FEATURES)

medians = train_num[FULL_FEATURES].median(numeric_only=True)
X_train = train_num[FULL_FEATURES].fillna(medians)
X_test_actual   = testA_num[FULL_FEATURES].fillna(medians)
X_test_inferred = testI_num[FULL_FEATURES].fillna(medians)

y_train = train[TARGET].astype(int).values
y_test_actual   = test_actual[TARGET].astype(int).values
y_test_inferred = test_inferred[TARGET].astype(int).values

# -----------------------------
# Fit once on training, evaluate on both test sets
# -----------------------------
metrics_actual   = fit_and_eval(X_train, y_train, X_test_actual,   y_test_actual)
metrics_inferred = fit_and_eval(X_train, y_train, X_test_inferred, y_test_inferred)

print("Test metrics using ACTUAL 2024+ features:")
print(metrics_actual)
print("\nTest metrics using INFERRED 2024+ features:")
print(metrics_inferred)

# Optional: assert they match within tolerance
tol = 1e-6
for k in metrics_actual:
    if abs(metrics_actual[k] - metrics_inferred[k]) <= tol:
        print(f"{k}: match within tolerance ({metrics_actual[k]:.6f} vs {metrics_inferred[k]:.6f})")
    else:
        print(f"{k}: DIFFERENT ({metrics_actual[k]:.6f} vs {metrics_inferred[k]:.6f})")